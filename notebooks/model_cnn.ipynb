{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import threading\n",
    "import queue\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import misc\n",
    "from sklearn import model_selection, preprocessing, metrics\n",
    "from sklearn.utils import shuffle\n",
    "from skimage import transform\n",
    "from tqdm import tqdm\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras import backend as K\n",
    "from keras.losses import binary_crossentropy\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '/kaggle/dev/carvana-image-masking-challenge-data'\n",
    "RAW_DATA_PATH = os.path.join(DATA_PATH, 'raw_data')\n",
    "TRAIN_PATH = os.path.join(RAW_DATA_PATH, 'train')\n",
    "TEST_PATH = os.path.join(RAW_DATA_PATH, 'test')\n",
    "TRAIN_MASKS_PATH = os.path.join(RAW_DATA_PATH, 'train_masks')\n",
    "#TRAIN_MASKS_FIXED_PATH = os.path.join(DATA_PATH, 'fixed_masks/fix-HCK')\n",
    "TRAIN_MASKS_CSV_PATH = os.path.join(RAW_DATA_PATH, 'train_masks.csv')\n",
    "SAMPLE_SUBMISSION_PATH = os.path.join(RAW_DATA_PATH, 'sample_submission.csv')\n",
    "METADATA_PATH = os.path.join(RAW_DATA_PATH, 'metadata.csv')\n",
    "SUBMISSION_PATH = os.path.join(DATA_PATH, 'submissions')\n",
    "ASSETS_PATH = os.path.join(DATA_PATH, 'assets')\n",
    "MODELS_PATH = os.path.join(ASSETS_PATH, 'models')\n",
    "TENSORBOARD_PATH = os.path.join(ASSETS_PATH, 'tensorboard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_masks_df = pd.read_csv(TRAIN_MASKS_CSV_PATH)\n",
    "print('train_masks_df.shape', train_masks_df.shape)\n",
    "train_masks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "HEIGHT_ORIG = 1280\n",
    "WIDTH_ORIG = 1918\n",
    "CHANNELS_ORIG = 3\n",
    "\n",
    "HEIGHT = 1024\n",
    "WIDTH = 1024\n",
    "CHANNELS = 3\n",
    "new_shape = (HEIGHT, WIDTH, CHANNELS)\n",
    "mask_shape = (new_shape[0], new_shape[1], 1)\n",
    "\n",
    "def get_img_id(img_path):\n",
    "    return img_path[:15]\n",
    "\n",
    "img_ids = list(map(get_img_id, list(train_masks_df.img.values)))\n",
    "\n",
    "def load_image_disk(img_id, folder=TRAIN_PATH):\n",
    "    img = misc.imread(os.path.join(folder, img_id + \".jpg\"))\n",
    "    return img\n",
    "\n",
    "def get_image(img_id):\n",
    "    return train_imgs[img_id]\n",
    "\n",
    "# Return mask as 1/0 binary img with single channel\n",
    "def load_mask_disk(img_id, folder=TRAIN_MASKS_PATH, filetype='gif'):\n",
    "    mask = misc.imread(os.path.join(folder,  \"{}_mask.{}\".format(img_id, filetype)), flatten=True)\n",
    "    mask[mask > 128] = 1\n",
    "    if len(mask.shape) == 2:\n",
    "        mask = mask.reshape(mask.shape[0], mask.shape[1], 1)\n",
    "    return mask\n",
    "\n",
    "def get_mask(img_id):\n",
    "    return train_masks[img_id]\n",
    "\n",
    "# Helper functions to plot car, mask, masked_car\n",
    "def plot_image(img_id):\n",
    "    img = misc.imread(os.path.join(TRAIN_PATH, img_id + \".jpg\"))\n",
    "    imgplot = plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_mask(img_id, folder=TRAIN_MASKS_PATH, filetype='gif', ax=None):\n",
    "    mask = misc.imread(os.path.join(folder, \"{}_mask.{}\".format(img_id, filetype)))\n",
    "    if ax == None:\n",
    "        imgplot = plt.imshow(mask)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    else:\n",
    "        ax.imshow(mask)\n",
    "        ax.axis('off')\n",
    "    \n",
    "def plot_masked_image(img_id, ax=None):\n",
    "    img = misc.imread(os.path.join(TRAIN_PATH, img_id + \".jpg\"))\n",
    "    mask = misc.imread(os.path.join(TRAIN_MASKS_PATH, img_id + \"_mask.gif\"))\n",
    "    mask = mask[:,:,0:3]\n",
    "    mask[mask == 255] = 1 \n",
    "    masked_img = img * mask\n",
    "    if ax == None:\n",
    "        imgplot = plt.imshow(masked_img)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    else:\n",
    "        ax.imshow(masked_img)\n",
    "        ax.axis('off')\n",
    "    \n",
    "def resize_img(img, new_s = new_shape):\n",
    "    return transform.resize(img, new_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training images into memory\n",
    "train_imgs = {}\n",
    "for img_path in tqdm(os.listdir(TRAIN_PATH)):\n",
    "    img_id = get_img_id(img_path)\n",
    "    train_imgs[img_id] = cv2.resize(load_image_disk(img_id), (new_shape[0], new_shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training masks into memory\n",
    "train_masks = {}\n",
    "for img_path in tqdm(os.listdir(TRAIN_MASKS_PATH)):\n",
    "    img_id = get_img_id(img_path)\n",
    "    train_masks[img_id] = np.expand_dims(cv2.resize(load_mask_disk(img_id), (new_shape[0], new_shape[1])), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def randomHueSaturationValue(image, hue_shift_limit=(-180, 180),\n",
    "#                              sat_shift_limit=(-255, 255),\n",
    "#                              val_shift_limit=(-255, 255), u=0.5):\n",
    "#     if np.random.random() < u:\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "#         h, s, v = cv2.split(image)\n",
    "#         hue_shift = np.random.uniform(hue_shift_limit[0], hue_shift_limit[1])\n",
    "#         h = cv2.add(h, hue_shift)\n",
    "#         sat_shift = np.random.uniform(sat_shift_limit[0], sat_shift_limit[1])\n",
    "#         s = cv2.add(s, sat_shift)\n",
    "#         val_shift = np.random.uniform(val_shift_limit[0], val_shift_limit[1])\n",
    "#         v = cv2.add(v, val_shift)\n",
    "#         image = cv2.merge((h, s, v))\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_HSV2RGB)\n",
    "#     return image\n",
    "\n",
    "# def randomShiftScaleRotate(image, mask,\n",
    "#                            shift_limit=(-0.0625, 0.0625),\n",
    "#                            scale_limit=(-0.1, 0.1),\n",
    "#                            rotate_limit=(-45, 45), aspect_limit=(0, 0),\n",
    "#                            borderMode=cv2.BORDER_REFLECT_101, u=0.5):\n",
    "#     if np.random.random() < u:\n",
    "#         height, width, channel = image.shape\n",
    "\n",
    "#         angle = np.random.uniform(rotate_limit[0], rotate_limit[1])  # degree\n",
    "#         scale = np.random.uniform(1 + scale_limit[0], 1 + scale_limit[1])\n",
    "#         aspect = np.random.uniform(1 + aspect_limit[0], 1 + aspect_limit[1])\n",
    "#         sx = scale * aspect / (aspect ** 0.5)\n",
    "#         sy = scale / (aspect ** 0.5)\n",
    "#         dx = round(np.random.uniform(shift_limit[0], shift_limit[1]) * width)\n",
    "#         dy = round(np.random.uniform(shift_limit[0], shift_limit[1]) * height)\n",
    "\n",
    "#         cc = np.math.cos(angle / 180 * np.math.pi) * sx\n",
    "#         ss = np.math.sin(angle / 180 * np.math.pi) * sy\n",
    "#         rotate_matrix = np.array([[cc, -ss], [ss, cc]])\n",
    "\n",
    "#         box0 = np.array([[0, 0], [width, 0], [width, height], [0, height], ])\n",
    "#         box1 = box0 - np.array([width / 2, height / 2])\n",
    "#         box1 = np.dot(box1, rotate_matrix.T) + np.array([width / 2 + dx, height / 2 + dy])\n",
    "\n",
    "#         box0 = box0.astype(np.float32)\n",
    "#         box1 = box1.astype(np.float32)\n",
    "#         mat = cv2.getPerspectiveTransform(box0, box1)\n",
    "#         image = cv2.warpPerspective(image, mat, (width, height), flags=cv2.INTER_LINEAR, borderMode=borderMode,\n",
    "#                                     borderValue=(0, 0, 0,))\n",
    "#         mask = cv2.warpPerspective(mask, mat, (width, height), flags=cv2.INTER_LINEAR, borderMode=borderMode,\n",
    "#                                    borderValue=(0, 0, 0,))\n",
    "#         if len(mask.shape) == 2:\n",
    "#             mask = np.expand_dims(mask, axis=2)\n",
    "\n",
    "#     return image, mask\n",
    "\n",
    "# def randomHorizontalFlip(image, mask, u=0.5):\n",
    "#     if np.random.random() < u:\n",
    "#         image = cv2.flip(image, 1)\n",
    "#         mask = cv2.flip(mask, 1)\n",
    "\n",
    "#     return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_training_batch(data, batch_size):\n",
    "    while True:\n",
    "        X_batch = []\n",
    "        Y_batch = []\n",
    "        batch_ids = np.random.choice(data,\n",
    "                                     size=batch_size,\n",
    "                                     replace=False)\n",
    "        for idx, img_id in enumerate(batch_ids):\n",
    "            x = get_image(img_id)\n",
    "            y = get_mask(img_id)\n",
    "#             x, y = randomShiftScaleRotate(x, y,\n",
    "#                                           shift_limit=(-0.0625, 0.0625),\n",
    "#                                           scale_limit=(-0.1, 0.1),\n",
    "#                                           rotate_limit=(-0, 0))\n",
    "#             x = randomHueSaturationValue(x,\n",
    "#                                hue_shift_limit=(-50, 50),\n",
    "#                                sat_shift_limit=(-5, 5),\n",
    "#                                val_shift_limit=(-15, 15))\n",
    "            X_batch.append(x)\n",
    "            Y_batch.append(y)\n",
    "        X = np.asarray(X_batch, dtype=np.float32)\n",
    "        Y = np.asarray(Y_batch, dtype=np.float32)\n",
    "        yield X, Y\n",
    "\n",
    "def generate_validation_batch(data, batch_size):\n",
    "    while True:\n",
    "        X_batch = []\n",
    "        Y_batch = []\n",
    "        batch_ids = np.random.choice(data,\n",
    "                                     size=batch_size,\n",
    "                                     replace=False)\n",
    "        for idx, img_id in enumerate(batch_ids):\n",
    "            x = get_image(img_id)\n",
    "            y = get_mask(img_id)\n",
    "            X_batch.append(x)\n",
    "            Y_batch.append(y)\n",
    "        X = np.asarray(X_batch, dtype=np.float32)\n",
    "        Y = np.asarray(Y_batch, dtype=np.float32)\n",
    "        yield X, Y\n",
    "\n",
    "def generate_validation_data_seq(data):\n",
    "    idx = 0\n",
    "    while True:\n",
    "        img_id = data[idx]\n",
    "        X = get_image(img_id)\n",
    "        Y = get_mask(img_id)\n",
    "        yield img_id, X, Y\n",
    "        idx  += 1\n",
    "        if idx >= len(data):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize impact of random shift scale rotate\n",
    "random_idx = np.random.randint(len(train_imgs.keys()))\n",
    "random_img_id = list(train_imgs.keys())[random_idx]\n",
    "plot_image(random_img_id)\n",
    "temp_img = get_image(random_img_id)\n",
    "mask = get_mask(random_img_id)\n",
    "temp_img, temp_mask = randomShiftScaleRotate(temp_img, mask,\n",
    "                              shift_limit=(-0.0625, 0.0625),\n",
    "                              scale_limit=(-0.1, 0.1),\n",
    "                              rotate_limit=(-0, 0))\n",
    "\n",
    "plt.imshow(temp_img * gray2rgb(temp_mask))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize impact of random hue saturation\n",
    "# random_idx = np.random.randint(len(train_imgs.keys()))\n",
    "# random_img_id = list(train_imgs.keys())[random_idx]\n",
    "plot_image(random_img_id)\n",
    "temp_img = cv2.imread(os.path.join(TRAIN_PATH, '{}.jpg'.format(random_img_id)))\n",
    "temp_img = randomHueSaturationValue(temp_img,\n",
    "                               hue_shift_limit=(-50, 50),\n",
    "                               sat_shift_limit=(-5, 5),\n",
    "                               val_shift_limit=(-15, 15))\n",
    "plt.imshow(temp_img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def down(filters, input_):\n",
    "    down_ = Conv2D(filters, (3, 3), padding='same')(input_)\n",
    "    down_ = BatchNormalization()(down_)\n",
    "    down_ = Activation('relu')(down_)\n",
    "    down_ = Conv2D(filters, (3, 3), padding='same')(down_)\n",
    "    down_ = BatchNormalization()(down_)\n",
    "    down_res = Activation('relu')(down_)\n",
    "    down_pool = MaxPooling2D((2, 2), strides=(2, 2))(down_)\n",
    "    return down_pool, down_res\n",
    "\n",
    "def up(filters, input_, down_):\n",
    "    up_ = UpSampling2D((2, 2))(input_)\n",
    "    up_ = concatenate([down_, up_], axis=3)\n",
    "    up_ = Conv2D(filters, (3, 3), padding='same')(up_)\n",
    "    up_ = BatchNormalization()(up_)\n",
    "    up_ = Activation('relu')(up_)\n",
    "    up_ = Conv2D(filters, (3, 3), padding='same')(up_)\n",
    "    up_ = BatchNormalization()(up_)\n",
    "    up_ = Activation('relu')(up_)\n",
    "    up_ = Conv2D(filters, (3, 3), padding='same')(up_)\n",
    "    up_ = BatchNormalization()(up_)\n",
    "    up_ = Activation('relu')(up_)\n",
    "    up_ = Conv2D(filters, (3, 3), padding='same')(up_)\n",
    "    up_ = BatchNormalization()(up_)\n",
    "    up_ = Activation('relu')(up_)\n",
    "    return up_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_unet_1024(input_shape=(HEIGHT, WIDTH, CHANNELS), num_classes=1):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    down0b, down0b_res = down(8, inputs)\n",
    "    down0a, down0a_res = down(16, down0b)\n",
    "    down0, down0_res = down(32, down0a)\n",
    "    down1, down1_res = down(64, down0)\n",
    "    down2, down2_res = down(128, down1)\n",
    "    down3, down3_res = down(256, down2)\n",
    "    down4, down4_res = down(512, down3)\n",
    "    \n",
    "    center = Conv2D(1024, (3, 3), padding='same')(down4)\n",
    "    center = BatchNormalization()(center)\n",
    "    center = Activation('relu')(center)\n",
    "    center = Conv2D(1024, (3, 3), padding='same')(center)\n",
    "    center = BatchNormalization()(center)\n",
    "    center = Activation('relu')(center)\n",
    "\n",
    "    up4 = up(512, center, down4_res)\n",
    "    up3 = up(256, up4, down3_res)\n",
    "    up2 = up(128, up3, down2_res)\n",
    "    up1 = up(64, up2, down1_res)\n",
    "    up0 = up(32, up1, down0_res)\n",
    "    up0a = up(16, up0, down0a_res)\n",
    "    up0b = up(8, up0a, down0b_res)\n",
    "\n",
    "    classify = Conv2D(num_classes, (1, 1), activation='sigmoid', name='final_layer')(up0b)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=classify)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    \n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "# def dice_coef_v2(y_true, y_pred, smooth=1):\n",
    "#     y_true_f = K.flatten(y_true)\n",
    "#     y_pred_f = K.flatten(y_pred)\n",
    "#     y_pred_f = K.greater_equal(y_pred_f, 0.5)\n",
    "    \n",
    "#     intersection = K.sum(y_true_f * y_pred_f)\n",
    "#     return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_coef_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def weighted_bce_loss(y_true, y_pred, weight):\n",
    "#     # avoiding overflow\n",
    "#     epsilon = 1e-7\n",
    "#     y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "#     logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "    \n",
    "#     # https://www.tensorflow.org/api_docs/python/tf/nn/weighted_cross_entropy_with_logits\n",
    "#     loss = (1. - y_true) * logit_y_pred + (1. + (weight - 1.) * y_true) * \\\n",
    "#     (K.log(1. + K.exp(-K.abs(logit_y_pred))) + K.maximum(-logit_y_pred, 0.))\n",
    "#     return K.sum(loss) / K.sum(weight)\n",
    "\n",
    "# def weighted_dice_coef(y_true, y_pred, weight):\n",
    "#     smooth = 1.\n",
    "#     w, m1, m2 = weight * weight, y_true, y_pred\n",
    "#     intersection = (m1 * m2)\n",
    "#     score = (2. * K.sum(w * intersection) + smooth) / (K.sum(w * m1) + K.sum(w * m2) + smooth)\n",
    "#     return score\n",
    "\n",
    "# def weighted_dice_loss(y_true, y_pred, weight):\n",
    "#     return 1. - weighted_dice_coef(y_true, y_pred, weight)\n",
    "\n",
    "# def weighted_bce_dice_loss(y_true, y_pred):\n",
    "#     y_true = K.cast(y_true, 'float32')\n",
    "#     y_pred = K.cast(y_pred, 'float32')\n",
    "#     # if we want to get same size of output, kernel size must be odd number\n",
    "#     averaged_mask = K.pool2d(\n",
    "#             y_true, pool_size=(41, 41), strides=(1, 1), padding='same', pool_mode='avg')\n",
    "#     border = K.cast(K.greater(averaged_mask, 0.01), 'float32') * K.cast(K.less(averaged_mask, 0.99), 'float32')\n",
    "#     weight = K.ones_like(averaged_mask)\n",
    "#     w0 = K.sum(weight)\n",
    "#     weight += border * 2\n",
    "#     w1 = K.sum(weight)\n",
    "#     weight *= (w0 / w1)\n",
    "#     loss = weighted_bce_loss(y_true, y_pred, weight) + \\\n",
    "#     weighted_dice_loss(y_true, y_pred, weight)\n",
    "#     return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ts = str(int(time.time()))\n",
    "model_name = 'malhot'\n",
    "num_epochs = 30\n",
    "steps_per_epoch = 1018\n",
    "run_name = 'model={}-batch_size={}-num_epoch={}-steps_per_epoch={}-ts={}'.format(model_name,\n",
    "                                                                          BATCH_SIZE,\n",
    "                                                                          num_epochs,\n",
    "                                                                          steps_per_epoch,\n",
    "                                                                          ts)\n",
    "tensorboard_loc = os.path.join(TENSORBOARD_PATH, run_name)\n",
    "checkpoint_loc = os.path.join(MODELS_PATH, 'model-{}-weights.h5'.format(ts))\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', \n",
    "                              patience=2, \n",
    "                              verbose=1, \n",
    "                              min_delta = 0.0001,\n",
    "                              mode='min',)\n",
    "\n",
    "modelCheckpoint = ModelCheckpoint(checkpoint_loc,\n",
    "                                  monitor = 'val_loss', \n",
    "                                  save_best_only = True, \n",
    "                                  mode = 'min', \n",
    "                                  verbose = 1,\n",
    "                                  save_weights_only = True)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=tensorboard_loc, histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "callbacks_list = [modelCheckpoint, earlyStopping, tensorboard]\n",
    "\n",
    "model = get_unet_1024()\n",
    "model.compile(loss=bce_dice_loss, optimizer=Adam(lr=0.0001), metrics=[dice_coef])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids, validation_ids = model_selection.train_test_split(img_ids, random_state=42, test_size=0.20)\n",
    "train_generator = generate_training_batch(train_ids, BATCH_SIZE)\n",
    "valid_generator = generate_validation_batch(validation_ids, BATCH_SIZE)\n",
    "VALIDATION_STEPS = int(len(validation_ids) / BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = get_unet_1024()\n",
    "# model.load_weights(os.path.join(MODELS_PATH, 'model-1505273667-weights.h5'))\n",
    "# model.compile(loss=bce_dice_loss, optimizer=Adam(1e-5), metrics=[dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Starting run {}'.format(run_name))\n",
    "history = model.fit_generator(\n",
    "        train_generator, \n",
    "        steps_per_epoch = steps_per_epoch, \n",
    "        epochs = num_epochs,\n",
    "        callbacks = callbacks_list,\n",
    "        verbose = 1,\n",
    "        validation_data = valid_generator,\n",
    "        validation_steps = VALIDATION_STEPS)\n",
    "\n",
    "model_path = os.path.join(MODELS_PATH, 'model-{}.h5'.format(ts))\n",
    "history_path = os.path.join(MODELS_PATH, 'model-{}.history'.format(ts))\n",
    "model.save(model_path)\n",
    "pickle.dump(history.history, open(history_path, \"wb\"))\n",
    "print('Saved model at {}'.format(model_path))\n",
    "print('Saved model history at {}'.format(history_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(os.path.join(MODELS_PATH, 'model-1505333320.h5'), custom_objects={'bce_dice_loss': bce_dice_loss,\n",
    "                                                                                    'dice_coef': dice_coef})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.evaluate_generator(valid_generator, VALIDATION_STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error analysis on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validation_dices = []\n",
    "for img_id, X, Y in generate_validation_data_seq(validation_ids):\n",
    "    error = model.evaluate(np.expand_dims(X, axis=0), np.expand_dims(Y, axis=0), verbose=0)\n",
    "    validation_dices.append((img_id, error[0], error[1]))\n",
    "\n",
    "val_eval_df = pd.DataFrame.from_records(validation_dices, columns=['img_id', 'val_loss', 'dice_coef'])\n",
    "val_eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_eval_df.to_csv(os.path.join(ASSETS_PATH, 'val_eval_df-1505408279.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_eval_df = pd.read_csv(os.path.join(ASSETS_PATH, 'val_eval_df-1505408279.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.distplot(val_eval_df['dice_coef'], kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(val_eval_df['dice_coef'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(val_eval_df['dice_coef'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(val_eval_df['dice_coef'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_outliers(data, col, m=2):\n",
    "    return data[(data[col] - np.mean(data[col])) < -1.0 * (m * np.std(data[col]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outlier_df = get_outliers(val_eval_df, 'dice_coef', 2)\n",
    "outlier_df = outlier_df.sort_values('dice_coef')\n",
    "print(outlier_df.shape)\n",
    "outlier_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img_id in outlier_df.img_id.tolist():\n",
    "    print(img_id, outlier_df[outlier_df.img_id == img_id].values.tolist()[0][2])\n",
    "    test_img = get_image(img_id)\n",
    "\n",
    "    # Plot original image\n",
    "    actual_img = load_image_disk(img_id)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(actual_img)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Predict mask\n",
    "    pred_mask = model.predict(np.expand_dims(test_img, axis=0))\n",
    "    \n",
    "    # Plot predicted mask\n",
    "    pred_mask = np.squeeze(pred_mask)    \n",
    "    pred_mask = resize_img(pred_mask, (HEIGHT_ORIG, WIDTH_ORIG))\n",
    "    pred_mask[pred_mask <= 0.5] = 0\n",
    "    pred_mask[pred_mask > 0.5] = 1\n",
    "    \n",
    "    # Plot ground truth mask\n",
    "    mask = load_mask_disk(img_id)\n",
    "    mask = np.squeeze(mask)\n",
    "    mask = resize_img(mask, (HEIGHT_ORIG, WIDTH_ORIG))\n",
    "        \n",
    "    # Plot intersection (true_positives) of two masks\n",
    "    true_positives = pred_mask * mask\n",
    "    \n",
    "    # Plot false positives (pred_mask == 1 && mask == 0)\n",
    "    false_positives = np.zeros_like(mask)\n",
    "    false_positives[(pred_mask == 1) & (mask == 0)] = 1\n",
    "    \n",
    "    # Plot false negatives (pred_mask == 0 && mask == 1)\n",
    "    false_negatives = np.zeros_like(mask)\n",
    "    false_negatives[(pred_mask == 0) & (mask == 1)] = 1\n",
    "\n",
    "    # Plot true negatives (pred_mask == 0 && mask == 0)\n",
    "    true_negatives = np.zeros_like(mask)\n",
    "    true_negatives[(pred_mask == 0) & (mask == 0)] = 1\n",
    "    \n",
    "    # Plot merged mask \n",
    "    # Legend: \n",
    "    #   Red: false positives \n",
    "    #   Green: true positives\n",
    "    #   Blue: false negatives\n",
    "    #   Black: true negatives\n",
    "    #   White: background (unclassified pixels) - this should never be visible\n",
    "    rgb_merged_mask = np.zeros((HEIGHT_ORIG, WIDTH_ORIG, CHANNELS_ORIG))\n",
    "    rgb_merged_mask = 255 # White\n",
    "    rgb_true_positives = gray2rgb(true_positives)\n",
    "    rgb_false_positives = gray2rgb(false_positives)\n",
    "    rgb_false_negatives = gray2rgb(false_negatives)\n",
    "    rgb_true_negatives = gray2rgb(true_negatives)\n",
    "\n",
    "    rgb_merged_mask = rgb_true_positives + rgb_false_positives + rgb_false_negatives + rgb_true_negatives\n",
    "    rgb_merged_mask[true_positives == 1] = [0, 255, 0] # Green\n",
    "    rgb_merged_mask[false_positives == 1] = [255, 0, 0] # Red\n",
    "    rgb_merged_mask[false_negatives == 1] = [0, 0, 255] # Blue\n",
    "    rgb_merged_mask[true_negatives == 1] = [0, 0, 0] # Black\n",
    "    \n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(rgb_merged_mask)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper methods\n",
    "def rle_encode(mask_image):\n",
    "    pixels = mask_image.flatten()\n",
    "    # We avoid issues with '1' at the start or end (at the corners of \n",
    "    # the original image) by setting those pixels to '0' explicitly.\n",
    "    # We do not expect these to be non-zero for an accurate mask, \n",
    "    # so this should not harm the score.\n",
    "    pixels[0] = 0\n",
    "    pixels[-1] = 0\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    runs[1::2] = runs[1::2] - runs[:-1:2]\n",
    "    return runs\n",
    "\n",
    "def rle_decode(mask_rle, shape):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)\n",
    "\n",
    "def rle_to_string(runs):\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def gray2rgb(img):\n",
    "    img = np.squeeze(img)\n",
    "    w, h = img.shape\n",
    "    ret = np.empty((w, h, 3), dtype=np.uint8)\n",
    "    ret[:, :, 0] = img\n",
    "    ret[:, :, 1] = img\n",
    "    ret[:, :, 2] = img\n",
    "    return ret\n",
    "\n",
    "def load_imgs(img_ids, folder=TRAIN_PATH):\n",
    "    imgs = []\n",
    "    for img_id in img_ids:\n",
    "        img = misc.imread(os.path.join(folder, img_id + \".jpg\"))\n",
    "        imgs.append(img)\n",
    "    return np.asarray(imgs)\n",
    "\n",
    "def resize_imgs(imgs, factor=0.1):\n",
    "    resized_imgs = []\n",
    "    for img in imgs:\n",
    "        resized_img = rescale(img, factor)\n",
    "        resized_imgs.append(resized_img)\n",
    "    return np.asarray(resized_imgs)\n",
    "\n",
    "def rescale_and_clean_masks(masks):\n",
    "    clean_masks = np.zeros((masks.shape[0], HEIGHT_ORIG, WIDTH_ORIG, 1), dtype=np.uint8)\n",
    "    for i in range(masks.shape[0]):        \n",
    "        mask = resize(masks[i], (HEIGHT_ORIG, WIDTH_ORIG, 1))\n",
    "        mask[mask <= 0.5] = 0\n",
    "        mask[mask > 0.5] = 1\n",
    "        clean_masks[i] = mask\n",
    "    return clean_masks\n",
    "\n",
    "def rle_masks(masks):  \n",
    "    rles = []\n",
    "    for i in range(masks.shape[0]):\n",
    "        rles.append(rle_to_string(rle_encode(masks[i])))\n",
    "    return rles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(os.path.join(MODELS_PATH, 'model-1505333320.h5'), custom_objects={'bce_dice_loss': bce_dice_loss,\n",
    "                                                                                    'dice_coef': dice_coef})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = get_unet_1024()\n",
    "model.load_weights(os.path.join(MODELS_PATH, 'model-1505408279-weights.h5'))\n",
    "model.compile(loss=bce_dice_loss, optimizer=Adam(1e-5), metrics=[dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for img_path in os.listdir(TEST_PATH)[1000:1005]:\n",
    "    #print(img_id, outlier_df[outlier_df.img_id == img_id].values.tolist()[0][2])\n",
    "    #test_img = get_image(img_id)\n",
    "    img_id = get_img_id(img_path)\n",
    "    \n",
    "    # Plot original image\n",
    "    actual_img = load_image_disk(img_id, TEST_PATH)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(actual_img)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    test_img_cv2 = cv2.resize(actual_img, (new_shape[0], new_shape[1]))\n",
    "    \n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(test_img_r)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(test_img_cv2)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Predict mask\n",
    "    pred_mask = model.predict(np.expand_dims(test_img_cv2, axis=0))\n",
    "    \n",
    "    # Plot predicted mask\n",
    "    pred_mask = np.squeeze(pred_mask)    \n",
    "    pred_mask = resize_img(pred_mask, (HEIGHT_ORIG, WIDTH_ORIG))\n",
    "    pred_mask[pred_mask <= 0.5] = 0\n",
    "    pred_mask[pred_mask > 0.5] = 1\n",
    "    \n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(pred_mask)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TEST_BATCH_SIZE = 16\n",
    "# NUM_BATCHES = int(math.ceil(len(test_img_ids) / TEST_BATCH_SIZE))\n",
    "\n",
    "# result = []\n",
    "# for batch in tqdm(range(NUM_BATCHES)):\n",
    "#     start = batch * TEST_BATCH_SIZE\n",
    "#     end = start + TEST_BATCH_SIZE\n",
    "#     end = len(test_img_ids) if end > len(test_img_ids) else end\n",
    "#     test_imgs = load_imgs(test_img_ids[start:end], TEST_PATH)\n",
    "#     resized_test_imgs = resize_imgs(test_imgs)\n",
    "#     pred_masks = model.predict(resized_test_imgs)\n",
    "#     clean_masks = rescale_and_clean_masks(pred_masks)\n",
    "#     rles = rle_masks(clean_masks)\n",
    "#     result.extend(zip(test_img_paths[start:end], rles))\n",
    "\n",
    "# sub_ts = str(int(time.time()))\n",
    "# submission_df = pd.DataFrame.from_records(result, columns=['img', 'rle_mask'])\n",
    "# sub_file_path = os.path.join(SUBMISSION_PATH, 'malhot-submission-{}.csv'.format(sub_ts))\n",
    "# submission_df.to_csv(sub_file_path, index=False)\n",
    "# print('Generated submission {}'.format(sub_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reduce random dots in output masks\n",
    "# new_result = []\n",
    "# for idx in tqdm(range(len(result))):\n",
    "#     img_path = result[idx][0]\n",
    "#     mask = result[idx][1]\n",
    "#     rle_decoded_mask = rle_decode(mask, (HEIGHT_ORIG, WIDTH_ORIG, 1))\n",
    "#     limg = measure.label(rle_decoded_mask)\n",
    "#     props = measure.regionprops(limg)\n",
    "#     props = sorted(props, key=lambda p: -p.area)\n",
    "#     # Erase all except the biggest blob\n",
    "#     rle_decoded_mask &= (limg == props[0].label)\n",
    "#     new_result.append((img_path, rle_to_string(rle_encode(rle_decoded_mask))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sub_ts = str(int(time.time()))\n",
    "# submission_df = pd.DataFrame.from_records(new_result, columns=['img', 'rle_mask'])\n",
    "# sub_file_path = os.path.join(SUBMISSION_PATH, 'malhot-submission-{}.csv'.format(sub_ts))\n",
    "# submission_df.to_csv(sub_file_path, index=False)\n",
    "# print('Generated submission {}'.format(sub_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Multi GPU inference code\n",
    "\n",
    "sample_submission_df = pd.read_csv(SAMPLE_SUBMISSION_PATH)\n",
    "input_size = HEIGHT\n",
    "batch_size = 4\n",
    "orig_width = WIDTH_ORIG\n",
    "orig_height = HEIGHT_ORIG\n",
    "threshold = 0.5\n",
    "\n",
    "gpus = [x.name for x in device_lib.list_local_devices() if x.name[:4] == '/gpu']\n",
    "\n",
    "df_test = pd.read_csv(SAMPLE_SUBMISSION_PATH)\n",
    "ids_test = df_test['img'].map(lambda s: s.split('.')[0])\n",
    "\n",
    "names = []\n",
    "rles = []\n",
    "q_size = 10\n",
    "\n",
    "for id in ids_test:\n",
    "    names.append('{}.jpg'.format(id))\n",
    "\n",
    "# https://www.kaggle.com/stainsby/fast-tested-rle\n",
    "def run_length_encode(mask):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    inds = mask.flatten()\n",
    "    runs = np.where(inds[1:] != inds[:-1])[0] + 2\n",
    "    runs[1::2] = runs[1::2] - runs[:-1:2]\n",
    "    rle = ' '.join([str(r) for r in runs])\n",
    "    return rle\n",
    "\n",
    "def create_model(gpu):\n",
    "    with tf.device(gpu):\n",
    "        model = get_unet_1024()\n",
    "    model.load_weights(os.path.join(MODELS_PATH, 'model-1505333320-weights.h5'))\n",
    "    return model\n",
    "\n",
    "def data_loader(q, ):\n",
    "    for start in tqdm(range(0, len(ids_test), batch_size)):\n",
    "        x_batch = []\n",
    "        end = min(start + batch_size, len(ids_test))\n",
    "        ids_test_batch = ids_test[start:end]\n",
    "        for id in ids_test_batch.values:\n",
    "            img = load_image_disk(id, TEST_PATH)\n",
    "            if input_size is not None:\n",
    "                img = cv2.resize(img, (input_size, input_size))\n",
    "            x_batch.append(img)\n",
    "        x_batch = np.array(x_batch, np.float32)\n",
    "        q.put((ids_test_batch, x_batch))\n",
    "    for g in gpus:\n",
    "        q.put((None, None))\n",
    "\n",
    "def predictor(q, gpu):\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth=True\n",
    "    sess = tf.Session(config=config)\n",
    "    with sess.as_default():\n",
    "        model = create_model(gpu)\n",
    "        while True:\n",
    "            ids, x_batch = q.get()\n",
    "            if ids is None:\n",
    "                break\n",
    "            preds = model.predict_on_batch(x_batch)\n",
    "            preds = np.squeeze(preds, axis=3)\n",
    "            for i,pred in enumerate(preds):\n",
    "                if input_size is not None:\n",
    "                    prob = cv2.resize(pred, (orig_width, orig_height))\n",
    "                else:\n",
    "                    prob = pred\n",
    "                mask = prob > threshold\n",
    "                rle = run_length_encode(mask)\n",
    "                id = ids.iloc[i]\n",
    "                rles.append((id, rle))\n",
    "\n",
    "print('Predicting on {} samples with batch_size = {}...'.format(len(ids_test), batch_size))\n",
    "q = queue.Queue(maxsize=q_size)\n",
    "threads = []\n",
    "threads.append(threading.Thread(target=data_loader, name='DataLoader', args=(q,)))\n",
    "threads[0].start()\n",
    "for gpu in gpus:\n",
    "    print(\"Starting predictor at device \" + gpu)\n",
    "\n",
    "    t = threading.Thread(target=predictor, name='Predictor', args=(q, gpu))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "# Wait for all threads to finish\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "sub_ts = str(int(time.time()))\n",
    "submission_df = pd.DataFrame(rles, columns=['img', 'rle_mask'])\n",
    "submission_df['img'] += '.jpg'\n",
    "sub_file_path = os.path.join(SUBMISSION_PATH, 'malhot-submission-{}.csv.gz'.format(sub_ts))\n",
    "submission_df.to_csv(sub_file_path, index=False, compression='gzip')\n",
    "print('Generated submission {}'.format(sub_file_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
